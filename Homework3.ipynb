{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Homework 3 - Name, SCIPER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this homework, we are going to work with the transformer. There are three parts of this homework.\n",
        "\n",
        "- In the first part, we are going to implement **positional encoding** and **self-attention**  and test them on a simple text dataset which contains around 100 sentences. We will use a small transformer in this task.\n",
        "\n",
        "- In the second part, we will detect promoters from the DNA sequences. The main difference compared to the previous task is to tokenize the DNA sequence. Thus, our task here is to build the **tokenizer** to tokenize the DNA sequence. For the model, we will continue using the small transformer.\n",
        "\n",
        "- In the third part, we will use a **foundation model** DNABERT to perform promoter detection. In this part, you do not need to train the transformer. Instead, you need to find and load the correct pre-trained model and then use it to get the embedding of the DNA sequence. Then, you will build a simple classifier to perform promoter detection based on the DNA embedding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Initialization\n",
        "\n",
        "Import the packages you are going to use here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from torchmetrics.classification import BinaryF1Score\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from types import SimpleNamespace\n",
        "from utils import data, evaluation, models, visualization, text_exercise\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set seeds\n",
        "seed = 128\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Positional Encoding and Self-Attention (7 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1. Sinusoidal Positional Encoding (1 pt)\n",
        "\n",
        "In this section, you are going to implement the sinusoidal positional encoding. The formula is as the following:\n",
        "\n",
        "<div>\n",
        "<img src=\"./imgs/positional embedding.png\" width=\"400\"/>\n",
        "</div>\n",
        "\n",
        "where $t$ is the desired position in the input and $\\mathsf{\\omega}_k$ follows:\n",
        "\n",
        "<div>\n",
        "<img src=\"./imgs/omega.png\" width=\"200\"/>\n",
        "</div>\n",
        "\n",
        "To see the details of sinusoidal positional encoding, you can check this [link](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self, max_position_embeddings, hidden_size, device):\n",
        "        super().__init__()\n",
        "\n",
        "        # Create a positional encoding matrix\n",
        "        position = torch.arange(max_position_embeddings).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, hidden_size, 2).float() * (-math.log(10000.0) / hidden_size))\n",
        "        positional_embedding = torch.zeros(max_position_embeddings, hidden_size)\n",
        "\n",
        "        positional_embedding[:, 0::2] = torch.sin(position * div_term)\n",
        "        positional_embedding[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.positional_embedding = positional_embedding.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.positional_embedding\n",
        "    \n",
        "    def embedding(self):\n",
        "        return self.positional_embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, you can visualize your positional encoding. If you implement everything correctly, you can get a figure that is similar to Figure 2 in this [link](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d2bee3f00b847e787bbe67fa8d84875",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(Dropdown(description='Sequence Length', index=2, options=(100, 500, 1000, 5000), style=Descript…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cc1e758431a4542b1967c72d25ecfd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "visualize_embedding, dimension_selector, max_len_selector = visualization.display_positional_encoding(PositionalEmbedding)\n",
        "ui = widgets.HBox([max_len_selector, dimension_selector])  \n",
        "out = widgets.interactive_output( visualize_embedding, {'max_len': max_len_selector, 'dimension': dimension_selector})\n",
        "display(ui, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. Self-Attention Mechanism (5 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, you are going to implement the self-attention mechanism. Please check the section 'Self-Attention in Detail' in this [link](https://jalammar.github.io/illustrated-transformer/) for the details of self-attention mechanism. (We encourage you to carefully go through the link since it is a very good tutorial for transformer.)\n",
        "\n",
        "The specific steps will be provided in the comments of the following code. (The steps are only for reference. You do need to follow the steps if you have a better way to implement it.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BertSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
        "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads)\n",
        "            )\n",
        "        self.output_attentions = config.output_attentions\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        # ToDo: initialize K, Q, V\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        # ToDo: add a dropout layer\n",
        "        # Hint: using config.attention_probs_dropout_prob as the dropout probability\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "    ):\n",
        "        # The parameter encoder_hidden_states and encoder_attention_mask is for cross-attention. \n",
        "        # We do not use them in this homework.\n",
        "\n",
        "        # ToDo: get the key, query, and value from the hidden_states\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        # ToDo: transpose K, Q, V to get the score\n",
        "        # Hint: using self.transpose_for_scores\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "        # ToDo: Get the raw attention score\n",
        "        # Hint: Lecture 05 transformers - Slide 23 - the part within the softmax\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        \n",
        "        # You do not need to change this part.\n",
        "        # Explanation of attention_mask: https://lukesalamone.github.io/posts/what-are-attention-masks/\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # ToDo: Normalize the attention scores to probabilities.\n",
        "        # Hint: \n",
        "        # 1. Lecture 05 transformers - Slide 23 - using softmax to get the probability\n",
        "        # 2. Use self.dropout to do the dropout\n",
        "\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # You do not need to change this part.\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        # ToDo: Multiply each value by the score\n",
        "        # Hint: \n",
        "        # 1. Lecture 05 transformers - Slide 23 - getting the final result\n",
        "        # 2. Permuting the result to the correct shape. If you do not know what should be the correct shape, you can print the shape of the tensors.\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        # print(f\"Hidden states shape: {hidden_states.shape}\")\n",
        "        # print(f\"Context layer before permuting {context_layer.shape}\")\n",
        "        # context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        # print(f\"Context layer after permuting {context_layer.shape}\")\n",
        "\n",
        "        # ---------\n",
        "        # For a single attention head TODO is this differentiation even still necessary after having all_head_size instead of attention_head_size?\n",
        "        if self.num_attention_heads == 1:\n",
        "            context_layer = context_layer.squeeze(1)  # Remove the singleton head dimension\n",
        "\n",
        "        # For multiple attention heads\n",
        "        else:\n",
        "            context_layer = context_layer.permute(0, 2, 1, 3).contiguous() # [batch_size, num_attention_heads, sequence_length, attention_head_size]\n",
        "            new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "            context_layer = context_layer.view(*new_context_layer_shape)\n",
        "\n",
        "        # Ensure the context layer shape now matches the hidden states shape\n",
        "        #print(f\"Context layer final shape: {context_layer.shape}\")\n",
        "\n",
        "        # ------\n",
        "\n",
        "        \n",
        "        # Get the output\n",
        "        outputs = (context_layer, attention_probs) if self.output_attentions else (context_layer,)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's test your implementation using simple text data! First, let's load the data.\n",
        "\n",
        "We use a small dataset in this homework for a shorter training time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ChatGPT generated text data about BERT\n",
        "text = text_exercise.get()\n",
        "sentences_df, vocab = data.to_sentence_df(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After loading the data, you can train your model. Here we train our model using masked token prediction.\n",
        "\n",
        "Hint: The final model accuracy should be higher than 0.9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable model parameters: 64910\n",
            "Epoch: 0020 loss = 4.319178\n",
            "Epoch: 0040 loss = 3.649581\n",
            "Epoch: 0060 loss = 3.068071\n",
            "Epoch: 0080 loss = 2.606092\n",
            "Epoch: 0100 loss = 2.191446\n",
            "Epoch: 0120 loss = 1.801577\n",
            "Epoch: 0140 loss = 1.378951\n",
            "Epoch: 0160 loss = 1.037766\n",
            "Epoch: 0180 loss = 0.758234\n",
            "Epoch: 0200 loss = 0.516631\n",
            "Final model accuracy: 0.9922480620155039\n"
          ]
        }
      ],
      "source": [
        "text_max_len = 11\n",
        "\n",
        "text_config = SimpleNamespace(\n",
        "        vocab_size=len(vocab),\n",
        "        hidden_size=60,\n",
        "        max_position_embeddings=text_max_len,\n",
        "        type_vocab_size=1,\n",
        "        layer_norm_eps=1e-12,\n",
        "        hidden_dropout_prob=0.0,\n",
        "        attention_probs_dropout_prob=0.0,\n",
        "        num_attention_heads=1,\n",
        "        hidden_act=\"gelu\",\n",
        "        intermediate_size=160,\n",
        "        num_hidden_layers=1,\n",
        "        is_decoder=False,\n",
        "        output_attentions=True,\n",
        "        output_hidden_states=False,\n",
        "        pruned_heads = {},\n",
        "        initializer_range=0.02,\n",
        "        device=\"cpu\"\n",
        "    )\n",
        "\n",
        "tokenizer = data.TextTokenizer(vocab)\n",
        "input_ids, segment_ids, masked_lm_labels, labels_idx, labels, attention_masks = data.generate_masked_data(sentences_df, tokenizer, k=1, max_len=text_max_len, noise_rate=0.4)\n",
        "\n",
        "model = models.BertForMaskedLM(config=text_config, positional_embedding=PositionalEmbedding, attention=BertSelfAttention)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "print(f\"Number of trainable model parameters: {models.number_of_model_parameters(model)}\")\n",
        "\n",
        "for epoch in range(200):\n",
        "    optimizer.zero_grad()\n",
        "    loss, outputs, attentions = model(\n",
        "        input_ids=input_ids,\n",
        "        token_type_ids=segment_ids,\n",
        "        masked_lm_labels=masked_lm_labels,\n",
        "        attention_mask=attention_masks\n",
        "    )\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f\"Final model accuracy: {evaluation.masked_label_accuracy(labels, labels_idx, outputs.data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3. Visualize Attention (1 pt)\n",
        "\n",
        "Here, you can visualize the self-attention. \n",
        "\n",
        "Question: Can you interpret the visualization of the self-attention?\n",
        "\n",
        "**Write down you answer here (1 pt):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a2bb70a8bc44281b5ba34589ceed89b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(Dropdown(description='Sample:', options=(5, 8, 11, 13, 18, 24, 26, 29, 31, 35, 37, 38, 6…"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "visualize_attention, sample_id_selector = visualization.display_attantion(attentions=attentions, input_ids=input_ids, tokenizer=tokenizer)\n",
        "widgets.interactive(visualize_attention, sample_id=sample_id_selector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4. Train on small Wikitext Dataset\n",
        "\n",
        "Here, you can **optionally** test your model on the smallest wikitext dataset. You should get an test accuracy around 0.4 after training 50 epochs.\n",
        "\n",
        "This part is only for you to test your code. You can choose to run it or not. It takes around 1 hour to train the model for 50 epochs on the smallest wikitext dataset with Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#text_exercise.train_wikitext(device, positional_embedding=PositionalEmbedding, attention=BertSelfAttention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Promoter detection (7 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we detect promoter in DNA sequence.\n",
        "\n",
        "A promoter is a region of DNA upstream of a gene where relevant proteins (such as RNA polymerase and transcription factors) bind to initiate transcription of that gene. Promoter detection is to identify if there are promoter regions in the given DNA sequence. We have covered this in the lecture. (If you are interested in the promoter, you can check this [link](https://www.genome.gov/genetics-glossary/Promoter) for more details.)\n",
        "\n",
        "Here, we use a transformer and a classifier. The transformer first embeds the DNA sequences into features, and then the classifier detects the promoter based on the features.\n",
        "\n",
        "The main difference between text and DNA sequence is how to tokenize the sequence. Thus, you need to implement a tokenizer for the DNA sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. DNA Tokenizer (1 pts)\n",
        "\n",
        "Here, you will implement the DNA tokenizer the same as in DNABERT. Please check this [paper](https://academic.oup.com/bioinformatics/article/37/15/2112/6128680) for implementation details. Also, you need to check the data type and shape for both input and output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DNATokenizer(data.Tokenizer):\n",
        "    def __init__(self, k, vocab, unknown=\"[UNK]\"):\n",
        "        super().__init__(vocab, unknown)\n",
        "\n",
        "        # self.k is the k of k-mers\n",
        "        self.k = k\n",
        "\n",
        "    def _parse_text(self, text):\n",
        "        \n",
        "        # ToDo: get the tokens\n",
        "        output = [text[i:i+self.k] for i in range(len(text) - self.k + 1)] #k-mers\n",
        "        # TODO check data type and shape for both input and output\n",
        "        # TODO Add CLS sign\n",
        "        return output\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. Test BERT on DNA Sequence\n",
        "\n",
        "In this section, you will train BERT on DNA sequence to learn the embedding of DNA sequence. The code is provided below and you do not need to write anything.\n",
        "\n",
        "Hint: the final evaluation accuracy should be higher than 0.2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable model parameters: 118869\n",
            "Epoch: 0010 train cost = 4.017668 eval cost = 4.066978\n",
            "Epoch: 0020 train cost = 3.854006 eval cost = 3.990574\n",
            "Epoch: 0030 train cost = 3.247480 eval cost = 3.409230\n",
            "Epoch: 0040 train cost = 2.916915 eval cost = 3.228085\n",
            "Epoch: 0050 train cost = 2.419423 eval cost = 2.758377\n",
            "Train Acc = 0.263742 Eval Acc = 0.181002\n"
          ]
        }
      ],
      "source": [
        "kmer = 3\n",
        "mask_length = kmer\n",
        "VOCAB_3MER = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"AAA\", \"AAT\", \"AAC\", \"AAG\", \"ATA\", \"ATT\", \"ATC\", \"ATG\", \"ACA\", \"ACT\", \"ACC\", \"ACG\", \"AGA\", \"AGT\", \"AGC\", \"AGG\", \"TAA\", \"TAT\", \"TAC\", \"TAG\", \"TTA\", \"TTT\", \"TTC\", \"TTG\", \"TCA\", \"TCT\", \"TCC\", \"TCG\", \"TGA\", \"TGT\", \"TGC\", \"TGG\", \"CAA\", \"CAT\", \"CAC\", \"CAG\", \"CTA\", \"CTT\", \"CTC\", \"CTG\", \"CCA\", \"CCT\", \"CCC\", \"CCG\", \"CGA\", \"CGT\", \"CGC\", \"CGG\", \"GAA\", \"GAT\", \"GAC\", \"GAG\", \"GTA\", \"GTT\", \"GTC\", \"GTG\", \"GCA\", \"GCT\", \"GCC\", \"GCG\", \"GGA\", \"GGT\", \"GGC\", \"GGG\" ]\n",
        "\n",
        "raw_training_data = data.load_csv(\"./data/train.csv\")\n",
        "raw_test_data = data.load_csv(\"./data/test.csv\")\n",
        "\n",
        "dna_max_len = 298\n",
        "batch_size = 128\n",
        "max_dna_mask = 100\n",
        "dataset_size = 1000\n",
        "num_layers = 3\n",
        "num_heads = 6\n",
        "dna_config = SimpleNamespace(\n",
        "        vocab_size=len(VOCAB_3MER),\n",
        "        hidden_size=60,\n",
        "        max_position_embeddings=dna_max_len,\n",
        "        type_vocab_size=1,\n",
        "        layer_norm_eps=1e-12,\n",
        "        hidden_dropout_prob=0.0,\n",
        "        attention_probs_dropout_prob=0.0,\n",
        "        num_attention_heads=num_heads,\n",
        "        hidden_act=\"gelu\",\n",
        "        intermediate_size=160,\n",
        "        num_hidden_layers=num_layers,\n",
        "        is_decoder=False,\n",
        "        output_attentions=True,\n",
        "        output_hidden_states=True,\n",
        "        pruned_heads = {},\n",
        "        initializer_range=0.02,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "tokenizer = DNATokenizer(k=kmer, vocab=VOCAB_3MER)\n",
        "input_ids, segment_ids, masked_lm_labels, labels_idx, labels, attention_masks = data.generate_masked_data(raw_training_data, tokenizer, max_len=dna_max_len, max_mask=max_dna_mask, k=mask_length, mask_rate=0.05, max_size=dataset_size)\n",
        "test_input_ids, test_segment_ids, test_masked_lm_labels, test_labels_idx, test_labels, test_attention_masks = data.generate_masked_data(raw_test_data, tokenizer, max_len=dna_max_len, max_mask=max_dna_mask, k=mask_length, mask_rate=0.05, max_size=dataset_size)\n",
        "\n",
        "model = models.BertForMaskedLM(config=dna_config, positional_embedding=PositionalEmbedding, attention=BertSelfAttention).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.002)\n",
        "print(f\"Number of trainable model parameters: {models.number_of_model_parameters(model)}\")\n",
        "\n",
        "train_dataset = TensorDataset(input_ids, segment_ids, masked_lm_labels, labels_idx, labels, attention_masks)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(test_input_ids, test_segment_ids, test_masked_lm_labels, test_labels_idx, test_labels, test_attention_masks)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for epoch in range(50):\n",
        "  total_train_loss = 0\n",
        "  model.train()\n",
        "  for batch_input_ids, batch_segment_ids, batch_masked_lm_labels, _, _, batch_attention_mask in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    loss, outputs, hidden_states, _ = model(\n",
        "        input_ids=batch_input_ids.to(device),\n",
        "        token_type_ids=batch_segment_ids.to(device),\n",
        "        masked_lm_labels=batch_masked_lm_labels.to(device),\n",
        "        attention_mask=batch_attention_mask.to(device)\n",
        "    )\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_train_loss += loss.item()\n",
        "  avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "    for batch_input_ids, batch_segment_ids, batch_masked_lm_labels, _, _, batch_attention_mask in test_loader:\n",
        "      with torch.no_grad():\n",
        "        loss, outputs, hidden_states, _ = model(\n",
        "          input_ids=batch_input_ids.to(device),\n",
        "          token_type_ids=batch_segment_ids.to(device),\n",
        "          masked_lm_labels=batch_masked_lm_labels.to(device),\n",
        "          attention_mask=batch_attention_mask.to(device)\n",
        "        )\n",
        "        if batch_attention_mask.sum() - torch.numel(batch_attention_mask) > 0 :\n",
        "          print(\"found patting\", batch_attention_mask.sum())\n",
        "        total_eval_loss += loss.item()\n",
        "    avg_eval_loss = total_eval_loss / len(test_loader)\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'train cost =', '{:.6f}'.format(avg_train_loss), 'eval cost =', '{:.6f}'.format(avg_eval_loss))\n",
        "\n",
        "average_train_acc, _ = evaluation.model_masked_label_accuracy(model, train_loader, device)\n",
        "average_test_acc, last_test_attention = evaluation.model_masked_label_accuracy(model, test_loader, device)\n",
        "print('Train Acc =', '{:.6f}'.format(average_train_acc), 'Eval Acc =', '{:.6f}'.format(average_test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. Visualize the Attentions (1 pt)\n",
        "\n",
        "Here, you can visualize the self-attention. \n",
        "\n",
        "Question: compare the visualization to Section 1.3, what can you find here? How do you explain it?\n",
        "\n",
        "**Write down you answer here (1 pt):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7307df08406845889d794191e9a45d8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(Dropdown(description='Sample:', options=(4, 13, 21, 25, 28, 30, 37, 38, 42, 45, 47, 50, 62, 77,…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc635ebcaf724ce99815743bdee6b1b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "visualize_attention, sample_id_selector, layer_selector, head_selector = visualization.display_multi_attantion(attentions=last_test_attention, tokenizer=tokenizer, input_ids=input_ids,  layers=range(1, num_layers+1),  heads=range(1, num_heads+1))\n",
        "ui = widgets.HBox([sample_id_selector, layer_selector, head_selector])  \n",
        "out = widgets.interactive_output(visualize_attention, {'sample_id': sample_id_selector, 'layer': layer_selector, 'head': head_selector})\n",
        "display(ui, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4. Use your pretrained model for promoter detection (5 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You already have the embeddings for the DNA sequence. Now, you are going to build a classifier based on the DNA embeddings. The classifier is to perform promoter detection. Specifically, the DNA sequence will be classified into *'contains promoter'* or *'does not contain promoter'*.\n",
        "\n",
        "Hint: \n",
        "- We now want to annotate data (get the label for each sample), not predict masked data anymore!\n",
        "- You can reuse some parts of the code in the previous sections, e.g. dataloader and training pipeline in Section 2.2.\n",
        "- If you implement the previous section correctly (the Eval Acc > 0.2 in Section 2.2), you already have an pre-trained object named 'model' of class models.BertForMaskedLM. You can directly use it.\n",
        "- The evaluation accuracy of this task should be around 0.6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ToDo: Define the classifier\n",
        "# Hint: We need only a binary classifier.\n",
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(in_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.fc(x))\n",
        "        return x\n",
        "    \n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, encoder, classifier):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.classifier = classifier\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.encoder(input_ids)[0]\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "        \n",
        "# ToDo: Freeze BERT parameters\n",
        "# Hint: \n",
        "# 1. BERT is the 'model' you have trained in Section 2.2.\n",
        "# 2. Check Exercise 1 to see how to freeze a model (set requires_grad to False)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Define model\n",
        "hidden_size = 60\n",
        "classifier = BinaryClassifier(hidden_size).to(device)\n",
        "model_n = CombinedModel(model.bert, classifier).to(device)\n",
        "\n",
        "# ToDo: Train your classifier\n",
        "# Hint: \n",
        "# 1. Write the training pipeline (dataloader, optimizer, training loop ...)\n",
        "# 2. You can reuse the code from Section 2.2.\n",
        "\n",
        "# Prepare and load data (without data mask)\n",
        "kmer = 3\n",
        "VOCAB_3MER = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"AAA\", \"AAT\", \"AAC\", \"AAG\", \"ATA\", \"ATT\", \"ATC\", \"ATG\", \"ACA\", \"ACT\", \"ACC\", \"ACG\", \"AGA\", \"AGT\", \"AGC\", \"AGG\", \"TAA\", \"TAT\", \"TAC\", \"TAG\", \"TTA\", \"TTT\", \"TTC\", \"TTG\", \"TCA\", \"TCT\", \"TCC\", \"TCG\", \"TGA\", \"TGT\", \"TGC\", \"TGG\", \"CAA\", \"CAT\", \"CAC\", \"CAG\", \"CTA\", \"CTT\", \"CTC\", \"CTG\", \"CCA\", \"CCT\", \"CCC\", \"CCG\", \"CGA\", \"CGT\", \"CGC\", \"CGG\", \"GAA\", \"GAT\", \"GAC\", \"GAG\", \"GTA\", \"GTT\", \"GTC\", \"GTG\", \"GCA\", \"GCT\", \"GCC\", \"GCG\", \"GGA\", \"GGT\", \"GGC\", \"GGG\" ]\n",
        "\n",
        "raw_training_data = data.load_csv(\"./data/train.csv\")\n",
        "raw_test_data = data.load_csv(\"./data/test.csv\")\n",
        "\n",
        "dna_max_len = 298\n",
        "batch_size = 128\n",
        "dataset_size = 1000\n",
        "\n",
        "tokenizer = DNATokenizer(k=kmer, vocab=VOCAB_3MER)\n",
        "input_ids, labels = data.generate_labeled_data(raw_training_data, tokenizer, max_len=dna_max_len, max_size=dataset_size)\n",
        "test_input_ids, test_labels = data.generate_labeled_data(raw_test_data, tokenizer, max_len=dna_max_len, max_size=dataset_size)\n",
        "\n",
        "train_dataset = TensorDataset(input_ids, labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataset = TensorDataset(test_input_ids, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=0.001)  # Only optimize classifier parameters\n",
        "print(f\"Number of trainable model parameters: {models.number_of_model_parameters(model_n)}\")\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(50):\n",
        "  total_train_loss = 0\n",
        "  model_n.train()\n",
        "  for batch_input_ids, batch_labels in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model_n(\n",
        "        batch_input_ids.to(device),\n",
        "        # token_type_ids=batch_segment_ids.to(device),\n",
        "        # masked_lm_labels=batch_masked_lm_labels.to(device),\n",
        "        # attention_mask=batch_attention_mask.to(device)\n",
        "    )\n",
        "    print(predictions)\n",
        "    loss = criterion(predictions, batch_labels.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_train_loss += loss.item()\n",
        "  avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    model_n.eval()\n",
        "    total_eval_loss = 0\n",
        "    for batch_input_ids, batch_labels in test_loader:\n",
        "      with torch.no_grad():\n",
        "        loss, outputs, hidden_states, _ = model_n(\n",
        "          batch_input_ids.to(device),\n",
        "          # token_type_ids=batch_segment_ids.to(device),\n",
        "          # masked_lm_labels=batch_masked_lm_labels.to(device),\n",
        "          # attention_mask=batch_attention_mask.to(device)\n",
        "        )\n",
        "        loss = criterion(predictions, batch_labels.to(device))\n",
        "        #if batch_attention_mask.sum() - torch.numel(batch_attention_mask) > 0 :\n",
        "        #  print(\"found patting\", batch_attention_mask.sum())\n",
        "        total_eval_loss += loss.item()\n",
        "    avg_eval_loss = total_eval_loss / len(test_loader)\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'train cost =', '{:.6f}'.format(avg_train_loss), 'eval cost =', '{:.6f}'.format(avg_eval_loss))\n",
        "\n",
        "average_train_acc, _ = evaluation.model_masked_label_accuracy(model_n, train_loader, device)\n",
        "average_test_acc, last_test_attention = evaluation.model_masked_label_accuracy(model_n, test_loader, device)\n",
        "print('Train Acc =', '{:.6f}'.format(average_train_acc), 'Eval Acc =', '{:.6f}'.format(average_test_acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5. Additional question (1 pt)\n",
        "\n",
        "Now we change mask_length = 1 (already changed, you do not need to implement anything).\n",
        "Let's run the code below and check the accuracy.\n",
        "\n",
        "Question: What is the final masked token prediction accuracy? How do you explain this?\n",
        "\n",
        "**Write down you answer here (1 pt):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kmer = 3\n",
        "mask_length = 1\n",
        "\n",
        "dna_max_len = 298\n",
        "batch_size = 128\n",
        "max_dna_mask = 100\n",
        "dataset_size = 1000\n",
        "num_layers = 3\n",
        "num_heads = 6\n",
        "dna_config = SimpleNamespace(\n",
        "        vocab_size=len(VOCAB_3MER),\n",
        "        hidden_size=60,\n",
        "        max_position_embeddings=dna_max_len,\n",
        "        type_vocab_size=1,\n",
        "        layer_norm_eps=1e-12,\n",
        "        hidden_dropout_prob=0.0,\n",
        "        attention_probs_dropout_prob=0.0,\n",
        "        num_attention_heads=num_heads,\n",
        "        hidden_act=\"gelu\",\n",
        "        intermediate_size=160,\n",
        "        num_hidden_layers=num_layers,\n",
        "        is_decoder=False,\n",
        "        output_attentions=True,\n",
        "        output_hidden_states=True,\n",
        "        pruned_heads = {},\n",
        "        initializer_range=0.02,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "tokenizer = DNATokenizer(k=3, vocab=VOCAB_3MER)\n",
        "input_ids, segment_ids, masked_lm_labels, labels_idx, labels, attention_masks = data.generate_masked_data(raw_training_data, tokenizer, max_len=dna_max_len, max_mask=max_dna_mask, k=mask_length, mask_rate=0.05, max_size=dataset_size)\n",
        "test_input_ids, test_segment_ids, test_masked_lm_labels, test_labels_idx, test_labels, test_attention_masks = data.generate_masked_data(raw_test_data, tokenizer, max_len=dna_max_len, max_mask=max_dna_mask, k=mask_length, mask_rate=0.05, max_size=dataset_size)\n",
        "\n",
        "model = models.BertForMaskedLM(config=dna_config, positional_embedding=PositionalEmbedding, attention=BertSelfAttention).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.002)\n",
        "print(f\"Number of trainable model parameters: {models.number_of_model_parameters(model)}\")\n",
        "\n",
        "train_dataset = TensorDataset(input_ids, segment_ids, masked_lm_labels, labels_idx, labels, attention_masks)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(test_input_ids, test_segment_ids, test_masked_lm_labels, test_labels_idx, test_labels, test_attention_masks)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for epoch in range(50):\n",
        "  total_train_loss = 0\n",
        "  model.train()\n",
        "  for batch_input_ids, batch_segment_ids, batch_masked_lm_labels, _, _, batch_attention_mask in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    loss, outputs, hidden_states, _ = model(\n",
        "        input_ids=batch_input_ids.to(device),\n",
        "        token_type_ids=batch_segment_ids.to(device),\n",
        "        masked_lm_labels=batch_masked_lm_labels.to(device),\n",
        "        attention_mask=batch_attention_mask.to(device)\n",
        "    )\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_train_loss += loss.item()\n",
        "  avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "    for batch_input_ids, batch_segment_ids, batch_masked_lm_labels, _, _, batch_attention_mask in test_loader:\n",
        "      with torch.no_grad():\n",
        "        loss, outputs, hidden_states, _ = model(\n",
        "          input_ids=batch_input_ids.to(device),\n",
        "          token_type_ids=batch_segment_ids.to(device),\n",
        "          masked_lm_labels=batch_masked_lm_labels.to(device),\n",
        "          attention_mask=batch_attention_mask.to(device)\n",
        "        )\n",
        "        if batch_attention_mask.sum() - torch.numel(batch_attention_mask) > 0 :\n",
        "          print(\"found patting\", batch_attention_mask.sum())\n",
        "        total_eval_loss += loss.item()\n",
        "    avg_eval_loss = total_eval_loss / len(test_loader)\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'train cost =', '{:.6f}'.format(avg_train_loss), 'eval cost =', '{:.6f}'.format(avg_eval_loss))\n",
        "\n",
        "average_train_acc, _ = evaluation.model_masked_label_accuracy(model, train_loader, device)\n",
        "average_test_acc, last_test_attention = evaluation.model_masked_label_accuracy(model, test_loader, device)\n",
        "print('Train Acc =', '{:.6f}'.format(average_train_acc), 'Eval Acc =', '{:.6f}'.format(average_test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Using foundation model (5 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1. Introduction\n",
        "\n",
        "In this section, we aim to use a foundation model, DNABERT, to perform promoter detection.\n",
        "A foundation model is a model pretrained on large datasets. Foundation models serve as the foundational building blocks upon which various applications can be constructed.\n",
        "\n",
        "Here, we use DNABERT as the foundation model. We first apply it on DNA sequence to get the embedding. Then, we train a classifier on the embedding as in Section 2. Please follow this [link](https://github.com/Zhihan1996/DNABERT_2) to load the foundation model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2. Implementation\n",
        "\n",
        "**Consider this situation:** You get a dataset about promoter detection, and you build your model to perform the task as in Section 2. However, the performance is not good since the model is not strong enough. Suddenly, you think we can use a large pre-trained model to embed DNA sequences. Then, you search online and find the pre-trained model [DNABERT](https://github.com/Zhihan1996/DNABERT_2). Now, you want to perform promoter detection using the pre-trained DNABERT.\n",
        "\n",
        "There is no coding framework in this section. Just make things work (get good test accuracy) using the pre-trained model!\n",
        "\n",
        "Hint: \n",
        "- We encourage you to create a **new environment** following the instructions of Section 3 in this [link](https://github.com/Zhihan1996/DNABERT_2). (When you face the error \"The model class you are passing has a config_class attribute that is not consistent with the config class you passed ...\", creating a new environment can save you.)\n",
        "- Section 4 in this [link](https://github.com/Zhihan1996/DNABERT_2) shows you how to load and use the pre-trained foundation model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "a. Load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ToDo: Load the train and test datasets from train.csv and test.csv\n",
        "# Hint: check Section 2.2.\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "raw_training_data = data.load_csv(\"./data/train.csv\") #def load_csv(filepath): return pd.read_csv(filepath)\n",
        "raw_test_data = data.load_csv(\"./data/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "b. Get the embeddings of the DNA sequences using pretrained model.\n",
        "\n",
        "Hint: \n",
        "- This step can take some time. Thus, you can start with a small sample size, and then increase it when you have made sure that everything works correctly.\n",
        "- After getting the embeddings, you can save them so that you can directly load them next time without running the foundation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.pooler.dense.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.pooler.dense.weight', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.value.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([768])\n",
            "torch.Size([768])\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, BertModel, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "config = BertConfig.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "model = BertModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", config=config, trust_remote_code=True)\n",
        "\n",
        "\n",
        "dna = [\"ACGTAGCATCGGATCTATCTATCGACACTTGGTTATCGATCTACGAGCATCTCGTTAGC\", \"ACGTAGCATCGGATCTATCTATCGACACTTGGTTATCGATCTACGAGCATCTCGTTAGC\"]\n",
        "inputs = tokenizer(dna, return_tensors = 'pt')[\"input_ids\"]\n",
        "hidden_states = model(inputs)[0] # [1, sequence_length, 768]\n",
        "\n",
        "# embedding with mean pooling\n",
        "embedding_mean = torch.mean(hidden_states[0], dim=0)\n",
        "print(embedding_mean.shape) # expect to be 768\n",
        "\n",
        "# embedding with max pooling\n",
        "embedding_max = torch.max(hidden_states[0], dim=0)[0]\n",
        "print(embedding_max.shape) # expect to be 768"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.pooler.dense.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.pooler.dense.weight', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.value.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, BertModel, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "config = BertConfig.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "model = BertModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", config=config, trust_remote_code=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hlleo\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(4096, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n) argument after ** must be a mapping, not Tensor",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\python-workspace\\DL_in_biomedicine\\Homework3\\Homework3.ipynb Cell 44\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python-workspace/DL_in_biomedicine/Homework3/Homework3.ipynb#X56sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings_mean, embeddings_max, all_labels\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python-workspace/DL_in_biomedicine/Homework3/Homework3.ipynb#X56sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# Get embeddings and labels\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/python-workspace/DL_in_biomedicine/Homework3/Homework3.ipynb#X56sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m train_embeddings_mean, train_embeddings_max, train_labels \u001b[39m=\u001b[39m calculate_embeddings(raw_training_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python-workspace/DL_in_biomedicine/Homework3/Homework3.ipynb#X56sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m test_embeddings_mean, test_embeddings_max, test_labels \u001b[39m=\u001b[39m calculate_embeddings(raw_test_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python-workspace/DL_in_biomedicine/Homework3/Homework3.ipynb#X56sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# Convert to DataFrames\u001b[39;00m\n",
            "\u001b[1;32md:\\python-workspace\\DL_in_biomedicine\\Homework3\\Homework3.ipynb Cell 44\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python-workspace/DL_in_biomedicine/Homework3/Homework3.ipynb#X56sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mhlleo\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python-workspace/DL_in_biomedicine/Homework3/Homework3.ipynb#X56sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/python-workspace/DL_in_biomedicine/Homework3/Homework3.ipynb#X56sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python-workspace/DL_in_biomedicine/Homework3/Homework3.ipynb#X56sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mlast_hidden_state\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python-workspace/DL_in_biomedicine/Homework3/Homework3.ipynb#X56sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Mean pooling\u001b[39;00m\n",
            "\u001b[1;31mTypeError\u001b[0m: BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(4096, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n) argument after ** must be a mapping, not Tensor"
          ]
        }
      ],
      "source": [
        "# ToDo: Load the pretrained DNABERT model and use this to get the embeddings of the train and test DNA sequences.\n",
        "# Hint: Check section Quick Start on https://github.com/Zhihan1996/DNABERT_2\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "batch_size = 128\n",
        "\n",
        "# Function to calculate embeddings\n",
        "def calculate_embeddings(dataframe):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    embeddings_mean = []\n",
        "    embeddings_max = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Tokenize the sequences and convert labels to tensor\n",
        "    inputs = tokenizer(dataframe['sequence'].tolist(), padding=True, truncation=True, return_tensors='pt') #padding=True, truncation=True,\n",
        "    labels = torch.tensor(dataframe['label'].tolist())\n",
        "\n",
        "    # DataLoader for batch processing\n",
        "    dataset = TensorDataset(inputs['input_ids'][:10], labels[:10])\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for inputs, labels in data_loader:\n",
        "        print(\"hlleo\")\n",
        "        with torch.no_grad():\n",
        "            output = model(**inputs)\n",
        "        hidden_states = output.last_hidden_state\n",
        "\n",
        "        # Mean pooling\n",
        "        mean_pooling = torch.mean(hidden_states, dim=1)\n",
        "        embeddings_mean.append(mean_pooling)\n",
        "\n",
        "        # Max pooling\n",
        "        max_pooling = torch.max(hidden_states, dim=1)[0]\n",
        "        embeddings_max.append(max_pooling)\n",
        "\n",
        "        # Collect labels\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    # Concatenate all batches\n",
        "    embeddings_mean = torch.cat(embeddings_mean, dim=0)\n",
        "    embeddings_max = torch.cat(embeddings_max, dim=0)\n",
        "    all_labels = torch.cat(all_labels, dim=0)\n",
        "\n",
        "    return embeddings_mean, embeddings_max, all_labels\n",
        "\n",
        "# Get embeddings and labels\n",
        "train_embeddings_mean, train_embeddings_max, train_labels = calculate_embeddings(raw_training_data)\n",
        "test_embeddings_mean, test_embeddings_max, test_labels = calculate_embeddings(raw_test_data)\n",
        "\n",
        "# Convert to DataFrames\n",
        "df_train_embeddings_mean = pd.DataFrame(train_embeddings_mean.numpy())\n",
        "df_train_embeddings_max = pd.DataFrame(train_embeddings_max.numpy())\n",
        "df_test_embeddings_mean = pd.DataFrame(test_embeddings_mean.numpy())\n",
        "df_test_embeddings_max = pd.DataFrame(test_embeddings_max.numpy())\n",
        "\n",
        "# Add labels as a column\n",
        "df_train_embeddings_mean['label'] = train_labels.numpy()\n",
        "df_train_embeddings_max['label'] = train_labels.numpy()\n",
        "df_test_embeddings_mean['label'] = test_labels.numpy()\n",
        "df_test_embeddings_max['label'] = test_labels.numpy()\n",
        "\n",
        "# Save to CSV\n",
        "df_train_embeddings_mean.to_csv('train_embeddings_mean.csv', index=False)\n",
        "df_train_embeddings_max.to_csv('train_embeddings_max.csv', index=False)\n",
        "df_test_embeddings_mean.to_csv('test_embeddings_mean.csv', index=False)\n",
        "df_test_embeddings_max.to_csv('test_embeddings_max.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ToDo: Using tsne or umap to visualize the embedding space.\n",
        "# Hint: you can import other packages here for visualization.\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from umap import UMAP\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example embeddings\n",
        "# embeddings = your DNABERT embeddings\n",
        "\n",
        "# t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "embeddings_tsne = tsne.fit_transform(embeddings)\n",
        "\n",
        "# UMAP\n",
        "umap = UMAP(n_components=2, random_state=42)\n",
        "embeddings_umap = umap.fit_transform(embeddings)\n",
        "\n",
        "# Function to plot embeddings\n",
        "def plot_embeddings(embeddings, title):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.scatter(embeddings[:, 0], embeddings[:, 1], alpha=0.5)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Component 1')\n",
        "    plt.ylabel('Component 2')\n",
        "    plt.show()\n",
        "\n",
        "# Plot t-SNE embeddings\n",
        "plot_embeddings(embeddings_tsne, \"t-SNE Visualization of DNABERT Embeddings\")\n",
        "\n",
        "# Plot UMAP embeddings\n",
        "plot_embeddings(embeddings_umap, \"UMAP Visualization of DNABERT Embeddings\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "c. Train a classifier.\n",
        "\n",
        "Hint: It is easy to overfit on the training set. Try to avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ToDo: Define your classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ToDo: Train your classifier"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "navigate_num": "#000000",
        "navigate_text": "#333333",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700",
        "sidebar_border": "#EEEEEE",
        "wrapper_background": "#FFFFFF"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "264px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
